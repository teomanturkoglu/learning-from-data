{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import f1_score as f1s\n",
    "import lightgbm as lgb\n",
    "import random as r\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Random seed for reproducibility\n",
    "r.seed(1)\n",
    "\n",
    "# Main function: Handles data loading, training, validation, and saving predictions\n",
    "def train_and_validate(train_data_path, train_labels_path, test_data_path, output_file):\n",
    "\n",
    "    train_data = np.load(train_data_path, allow_pickle=True).item()  # Training features\n",
    "    train_labels = pd.read_csv(train_labels_path)  # Training labels\n",
    "    test_data = np.load(test_data_path, allow_pickle=True).item()  # Test features\n",
    "\n",
    "    # Combine training features from different sources\n",
    "    X = np.hstack([\n",
    "        train_data['vit_feature'],\n",
    "        train_data['clip_feature'],\n",
    "        train_data['dino_feature']\n",
    "    ])\n",
    "    y = train_labels['label'].values\n",
    "\n",
    "    # Combine test features from different sources\n",
    "    X_test = np.hstack([\n",
    "        test_data['vit_feature'],\n",
    "        test_data['clip_feature'],\n",
    "        test_data['dino_feature']\n",
    "    ])\n",
    "\n",
    "    print(\"Combined Training Features:\", X.shape)\n",
    "    print(\"Combined Test Features:\", X_test.shape)\n",
    "\n",
    "    # 2. Feature Selection (Select top 2000 features)\n",
    "    print(\"\\nPerforming feature selection...\")\n",
    "    selector = SelectKBest(score_func=f_classif, k=2000)\n",
    "    X_reduced = selector.fit_transform(X, y)\n",
    "    X_test_reduced = selector.transform(X_test)  # Apply the same transformation to the test set\n",
    "\n",
    "    print(\"Reduced Training Features:\", X_reduced.shape)\n",
    "    print(\"Reduced Test Features:\", X_test_reduced.shape)\n",
    "\n",
    "    # 3. 5-Fold Cross Validation\n",
    "    print(\"\\nStarting 5-Fold Cross Validation...\")\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)  # 5-fold cross-validation\n",
    "    f1_scores = []\n",
    "\n",
    "    # Define models\n",
    "    lightgbm_model = lgb.LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        learning_rate=0.05,\n",
    "        random_state=1\n",
    "    )\n",
    "\n",
    "    mlp_model = MLPClassifier(\n",
    "        hidden_layer_sizes=(512, 256),  # Two layers: one with 512 neurons, one with 256 neurons\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=300,\n",
    "        random_state=1\n",
    "    )\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for train_index, val_index in kf.split(X_reduced):\n",
    "        # Create training and validation sets\n",
    "        X_train, X_val = X_reduced[train_index], X_reduced[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # Train LightGBM model and make predictions\n",
    "        lightgbm_model.fit(X_train, y_train)\n",
    "        y_pred_lgb = lightgbm_model.predict_proba(X_val)\n",
    "\n",
    "        # Train MLP model and make predictions\n",
    "        mlp_model.fit(X_train, y_train)\n",
    "        y_pred_mlp = mlp_model.predict_proba(X_val)\n",
    "\n",
    "        # Combine predictions (weighted average)\n",
    "        combined_preds = (3 * y_pred_lgb + 3 * y_pred_mlp) / 6\n",
    "        final_preds = np.argmax(combined_preds, axis=1)\n",
    "\n",
    "        # Calculate Macro F1 score\n",
    "        f1 = f1s(y_val, final_preds, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "        print(f\"Fold F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Calculate average F1 score\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    print(f\"\\nAverage F1 Score: {average_f1:.4f}\")\n",
    "\n",
    "    # 4. Make predictions on the test set\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    lightgbm_model.fit(X_reduced, y)\n",
    "    mlp_model.fit(X_reduced, y)\n",
    "\n",
    "    y_pred_lgb_test = lightgbm_model.predict_proba(X_test_reduced)\n",
    "    y_pred_mlp_test = mlp_model.predict_proba(X_test_reduced)\n",
    "\n",
    "    # Combine test predictions\n",
    "    combined_test_preds = (3 * y_pred_lgb_test + 3 * y_pred_mlp_test) / 6\n",
    "    final_test_preds = np.argmax(combined_test_preds, axis=1)\n",
    "\n",
    "    # Save predictions to file\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': range(len(final_test_preds)),\n",
    "        'Predicted': final_test_preds\n",
    "    })\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to '{output_file}'\")\n",
    "\n",
    "    return average_f1\n",
    "\n",
    "# Call the function\n",
    "average_f1 = train_and_validate(\"train_feats.npy\", \"train_labels.csv\", \"valtest_feats.npy\", \"final_submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
